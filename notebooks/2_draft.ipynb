{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting efficientnet\n",
      "  Downloading efficientnet-1.1.1-py3-none-any.whl (18 kB)\n",
      "Collecting keras-applications<=1.0.8,>=1.0.7\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 5.0 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: scikit-image in /opt/conda/lib/python3.7/site-packages (from efficientnet) (0.18.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.19.5)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (2.10.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.15.0)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (8.1.0)\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (2.5)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (2021.2.26)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (2.9.0)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (3.3.4)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (1.1.1)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (1.6.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.8.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.0->scikit-image->efficientnet) (4.4.2)\n",
      "Installing collected packages: keras-applications, efficientnet\n",
      "Successfully installed efficientnet-1.1.1 keras-applications-1.0.8\n"
     ]
    }
   ],
   "source": [
    "#I installe efficientnet for one of my tests but it did not perform well so it is not needed\n",
    "#source: https://keras.io/api/applications/efficientnet/\n",
    "\n",
    "!pip install efficientnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import efficientnet.tfkeras as efn\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function will send me a message ont elegram when the neural network is done fitting\n",
    "\n",
    "\n",
    "def telegram_bot_sendtext(bot_message):\n",
    "    bot_token = '1653403779:AAFxxs8vLirSm-nXejEvmHpBoASuZOO75D8'\n",
    "    bot_chatID = '1589422433'\n",
    "    send_text = 'https://api.telegram.org/bot' + bot_token + '/sendMessage?chat_id=' + bot_chatID + \\\n",
    "                '&parse_mode=MarkdownV2&text=' + bot_message\n",
    "    response = requests.get(send_text)\n",
    "    \n",
    "    return response.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##setting the directory from which I want to get my data\n",
    "\n",
    "data_dir = '../data/layer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the batch size\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "#The height and width of each of my images in 256 picels so I will hard code that\n",
    "\n",
    "img_height = 256\n",
    "img_width = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, test, splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18124 files belonging to 10 classes.\n",
      "Using 14500 files for training.\n"
     ]
    }
   ],
   "source": [
    "#Setting training set to 80% of my data\n",
    "#I'm using the batch_size, img_height, img_width\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18124 files belonging to 10 classes.\n",
      "Using 3624 files for validation.\n"
     ]
    }
   ],
   "source": [
    "#Setting testing set to be 20% of my data\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bacterial_spot', 'early_blight', 'healthy', 'late_blight', 'leaf_mold', 'leaf_septoria', 'mosaic_virus', 'spider_mites', 'target_spot', 'yellow_leaf_curl_virus']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer Set-up For Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the layer that will augment the data so I have mroe images to work from\n",
    "#The code flips horizontally, does a random rotation, and random zoom\n",
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    layers.experimental.preprocessing.RandomFlip(\"horizontal\", \n",
    "                                                 input_shape=(img_height, \n",
    "                                                              img_width,\n",
    "                                                              3)),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "    layers.experimental.preprocessing.RandomZoom(0.1),\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b0_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n",
      "16809984/16804768 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# efficient = efn.EfficientNetB0(weights='imagenet', include_top=False, \n",
    "#                        input_shape=(256, 256, 3))\n",
    "\n",
    "# for layer in efficient.layers[:]:\n",
    "#     layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building my model topology\n",
    "\n",
    "model = Sequential([\n",
    "  #First layer augments the data\n",
    "  data_augmentation,\n",
    "  #efficient,\n",
    "  #This layer rescales all pixels\n",
    "  layers.experimental.preprocessing.Rescaling(1./255),\n",
    "  #The remaining layers are added in random order with dropouts and regularization to reduce overfitting\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu', kernel_regularizer = l2(0.001)),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Dropout(0.5),  \n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(128, 3, padding = 'same', activation = 'relu'),\n",
    "  layers.Dropout(0.5),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Currently this is set to the default learning rate, but I have it here\n",
    "#so I have the option to change it if I see fit\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling model with the adam optimizer and learning rate I set int eh previous cell\n",
    "#Using accuracy as the metric\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential (Sequential)      (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "rescaling_1 (Rescaling)      (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 256, 256, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 128, 128, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 128, 128, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 64, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1310730   \n",
      "=================================================================\n",
      "Total params: 1,408,170\n",
      "Trainable params: 1,408,170\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Quick model summary to see what it will look like visually\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "57/57 [==============================] - 148s 3s/step - loss: 2.2138 - accuracy: 0.2483 - val_loss: 2.1592 - val_accuracy: 0.2953\n",
      "Epoch 2/50\n",
      "57/57 [==============================] - 147s 3s/step - loss: 2.1079 - accuracy: 0.2962 - val_loss: 2.1217 - val_accuracy: 0.2953\n",
      "Epoch 3/50\n",
      "57/57 [==============================] - 147s 3s/step - loss: 2.0662 - accuracy: 0.2980 - val_loss: 2.0545 - val_accuracy: 0.2969\n",
      "Epoch 4/50\n",
      "57/57 [==============================] - 145s 3s/step - loss: 1.9820 - accuracy: 0.3097 - val_loss: 1.9461 - val_accuracy: 0.3562\n",
      "Epoch 5/50\n",
      "57/57 [==============================] - 147s 3s/step - loss: 1.8423 - accuracy: 0.3953 - val_loss: 1.8242 - val_accuracy: 0.5251\n",
      "Epoch 6/50\n",
      "57/57 [==============================] - 146s 3s/step - loss: 1.7275 - accuracy: 0.4717 - val_loss: 1.7177 - val_accuracy: 0.5615\n",
      "Epoch 7/50\n",
      "57/57 [==============================] - 147s 3s/step - loss: 1.6343 - accuracy: 0.5125 - val_loss: 1.6395 - val_accuracy: 0.5712\n",
      "Epoch 8/50\n",
      "57/57 [==============================] - 147s 3s/step - loss: 1.5500 - accuracy: 0.5416 - val_loss: 1.5652 - val_accuracy: 0.5552\n",
      "Epoch 9/50\n",
      "57/57 [==============================] - 146s 3s/step - loss: 1.4861 - accuracy: 0.5586 - val_loss: 1.5653 - val_accuracy: 0.4981\n",
      "Epoch 10/50\n",
      "57/57 [==============================] - 146s 3s/step - loss: 1.4306 - accuracy: 0.5739 - val_loss: 1.5365 - val_accuracy: 0.4948\n",
      "Epoch 11/50\n",
      "57/57 [==============================] - 145s 3s/step - loss: 1.3600 - accuracy: 0.5911 - val_loss: 1.5418 - val_accuracy: 0.4699\n",
      "Epoch 12/50\n",
      "57/57 [==============================] - 145s 3s/step - loss: 1.2913 - accuracy: 0.6095 - val_loss: 1.5507 - val_accuracy: 0.4625\n",
      "Epoch 13/50\n",
      "57/57 [==============================] - 147s 3s/step - loss: 1.2481 - accuracy: 0.6176 - val_loss: 1.6637 - val_accuracy: 0.4360\n",
      "Epoch 14/50\n",
      "25/57 [============>.................] - ETA: 1:15 - loss: 1.2125 - accuracy: 0.6198"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")\n",
    "\n",
    "telegram_bot_sendtext('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-439d840fac03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "#This cell assigns the accuracy, val accuracy, loss, and val loss to variables\n",
    "#for plotting\n",
    "#Matplotlib is used to plot the loss and accuracy curves on the y axis and epochs on the x axis\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-4.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
